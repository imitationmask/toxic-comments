{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incredible-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from module.preprocessor import Preprocessor\n",
    "from module.model.naive_bayes import NBTrainer, NBPredictor\n",
    "from config import create_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-transaction",
   "metadata": {},
   "source": [
    "***read naive bayes config***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adapted-savannah",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing:\n",
      "  test_file: data/test.csv\n",
      "  train_file: data/train.csv\n",
      "training:\n",
      "  classifier: MultinomialNB\n",
      "  ngram_range: (1, 1)\n",
      "  random_state: 0\n",
      "  stop_words: english\n",
      "  test_size: 0.3\n",
      "  vectorizer: CountVectorizer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyper_params = create_config('naive_bayes')\n",
    "train_file = hyper_params['preprocessing']['train_file']\n",
    "test_file = hyper_params['preprocessing']['test_file']\n",
    "test_size = hyper_params['training']['test_size']\n",
    "random_state = hyper_params['training']['random_state']\n",
    "vectorizer_name = hyper_params['training']['vectorizer']\n",
    "ngram_range = ast.literal_eval(hyper_params['training']['ngram_range'])\n",
    "stop_words = hyper_params['training']['stop_words']\n",
    "classifier_name = hyper_params['training']['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-argument",
   "metadata": {},
   "source": [
    "***process train, test files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "graduate-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "X_train, Y = preprocessor.process_train_files(train_file)\n",
    "test_id, X_test = preprocessor.process_test_file(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-england",
   "metadata": {},
   "source": [
    "***train for a single category prediction only***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bizarre-franchise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB with vectorizer CountVectorizer predicts column toxic of training accuracy: 0.9468373997326203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtrainer = NBTrainer()\n",
    "nbtrainer.train_single_y(X_train, Y, 'toxic', test_size=test_size, random_state=random_state,\n",
    "                         vectorizer_name=vectorizer_name, ngram_range=ngram_range, stop_words=stop_words,\n",
    "                         classifier_name=classifier_name)\n",
    "\n",
    "# nbtrainer.train_single_y(X_train, Y, 'severe_toxic', test_size=test_size)\n",
    "# nbtrainer.train_single_y(X_train, Y, 'obscene', test_size=test_size)\n",
    "# nbtrainer.train_single_y(X_train, Y, 'threat', test_size=test_size)\n",
    "# nbtrainer.train_single_y(X_train, Y, 'insult', test_size=test_size)\n",
    "# nbtrainer.train_single_y(X_train, Y, 'identity_hate', test_size=test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-immune",
   "metadata": {},
   "source": [
    "***train for all y categories***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yellow-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, classifiers = nbtrainer.train(X_train, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-geography",
   "metadata": {},
   "source": [
    "***create prediction and save it***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liquid-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbpredictor = NBPredictor(vectorizer, classifiers)\n",
    "predictions = nbpredictor.predict(X_test)\n",
    "nbpredictor.save_prediction(test_id, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "private-toronto",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanationwhy the edits made under my username hardcore metallica fan were reverted they werent vandalisms just closure on some gas after i voted at new york dolls fac and please dont remove the template from the talk page since im retired now892053827\n",
      "\n",
      "toxic 1 severe_toxic 0 obscene 1 threat 0 insult 1 identity_hate 0\n"
     ]
    }
   ],
   "source": [
    "row = 0\n",
    "print(X_train[row])\n",
    "print('')\n",
    "print('toxic {} severe_toxic {} obscene {} threat {} insult {} identity_hate {}'.\n",
    "        format(predictions['toxic'][row], predictions['severe_toxic'][row], \n",
    "        predictions['obscene'][row], predictions['threat'][row], predictions['insult'][row], predictions['identity_hate'][row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-concern",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
